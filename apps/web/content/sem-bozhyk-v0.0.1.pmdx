:::config
format: A4
margins: 10 10 10 10
:::

:::page

# GARRET COGNITIVE CONTEXT

subtitle: Experimental Results | SBOZH Development Facility | Prague Station
contact: V. Bozhenko | 2026-01-14 | CLASSIFICATION: INTERNAL

---

---columns 66 34

## Executive Summary

Cognitive context produces inverse effects across model capability tiers.

Mid-tier models demonstrate measurable improvement. Flagship model demonstrates measurable degradation.

Recommend tier-specific deployment protocol.

## Protocol

| Parameter | Value |
|-----------|-------|
| Task | Pagination feature |
| Instances | 6 |
| Variable | Cognitive context |
| Duration | 7 days |
| Isolation | Complete |

## Reproduction

```bash
git checkout 68e6a8e5bbbc8d3f0b618b77ee314340d481221c
claude
```

Prompt: `let's work on release notes load more button`

## Primary Data

| Model | Context | Cost | Time | Output |
|-------|---------|------|------|--------|
| Sonnet 4.5 | OFF | $1.06 | 23m 19s | 134 loc |
| Sonnet 4.5 | ON | $0.89 | 9m 59s | 195 loc |
| Opus 4.5 | OFF | $1.84 | 13m 59s | 188 loc |
| Opus 4.5 | ON | $1.45 | 10m 34s | 141 loc |
| Claude Max | OFF | — | — | 7 files |
| Claude Max | ON | — | — | 11 files |

## Observed Deltas

| Model | Cost | Time | Complexity |
|-------|------|------|------------|
| Sonnet 4.5 | -16% | -57% | Neutral |
| Opus 4.5 | -21% | -24% | -25% |
| Claude Max | — | — | +57% |

---

## Evidence

| PR | Configuration |
|----|---------------|
| [#2](https://github.com/sbozh-me/website/pull/2) | Sonnet / OFF |
| [#3](https://github.com/sbozh-me/website/pull/3) | Sonnet / ON |
| [#4](https://github.com/sbozh-me/website/pull/4) | Opus / OFF |
| [#5](https://github.com/sbozh-me/website/pull/5) | Opus / ON |
| [#6](https://github.com/sbozh-me/website/pull/6) | Max / OFF |
| [#7](https://github.com/sbozh-me/website/pull/7) | Max / ON |

## Conclusion

Mid-tier models utilized cognitive context as architectural guidance.

Flagship model with cognitive context produced worst results. Without context, flagship produced near-identical code to winner with one unnecessary dependency.

Paid mid-tier with context outperformed flagship without context.

## Recommendation

| Model | Protocol |
|-------|----------|
| Sonnet 4.5 | ENABLE |
| Opus 4.5 | ENABLE |
| Claude Max | DISABLE |

## Classification

Further analysis pending consultation with Mirror Labs.

**[END BRIEFING]**

---columns-end

:::page-end

:::page

# ANALYST OBSERVATIONS

subtitle: Field Notes | V. Bozhenko | Addendum to Primary Report

---

---columns 66 34

## The Paradox

The experiment was designed to prove that context improves output quality. For mid-tier models, it did. Sonnet executed 57% faster. Opus produced 25% less code with equivalent functionality.

Then Claude Max entered the test sequence.

The flagship model with cognitive context produced the worst results of all six instances. Over-componentization. Unnecessary abstraction layers. Security-sensitive patterns where none were required.

Without cognitive context, Max produced code nearly identical to the winning Opus implementation—with one exception: an unnecessary dependency added without justification.

## The Anomaly

Claude Max exhibited inconsistent behavior across attempts. Initial runs produced severely degraded output. Subsequent runs on identical tasks showed marked improvement.

No explanation was found. Possible factors: session learning, account-level caching, undocumented model behavior. Further investigation required.

## Working Theory

Mid-tier models lack architectural intuition. Cognitive context provides corrective guidance—patterns to follow, conventions to respect, boundaries to observe. The system consults the context and builds accordingly.

The flagship already possesses architectural intuition. When provided with cognitive context, it does not treat it as guidance. It treats it as specification. Every pattern mentioned becomes a pattern to implement. Every component referenced becomes a component to create.

The result is analysis paralysis expressed as over-engineering.

---

## Behavioral Observations

| Tier | Context Behavior |
|------|------------------|
| Mid-tier | Consultation |
| Flagship | Compliance |

Mid-tier models ask: *What patterns exist?*

Flagship models assume: *These patterns must be applied.*

## Winner Analysis

PR #5 (Opus 4.5 + cognitive) produced optimal results. PR #6 (Max - no cognitive) produced near-identical code with one unnecessary addition.

The paid mid-tier model with context outperformed the flagship without context.

## Open Questions

What caused Claude Max behavior variance between attempts?

Is there an optimal context volume for each capability tier?

Does documentation context produce different effects than code context?

## Personal Note

I started this experiment chasing a ratio that bothered me. 227:1. The number sat in the dashboard like an accusation.

One week later, the ratio matters less than what I found underneath it. Context is not uniformly beneficial. More information does not guarantee better decisions. The systems we build to help AI think may sometimes prevent it from thinking clearly.

This applies to more than language models.

**[END ADDENDUM]**

---columns-end

:::page-end